{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8123978a-564a-48ec-9e66-8dd017bdabec",
   "metadata": {},
   "source": [
    "## Testing of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39bb86ac-1739-4482-b45b-b3661047f3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Sambalpuri:**\n",
      "‡¨ï‡≠á‡¨®‡≠ç‡¨§‡¨æ ‡¨Ö‡¨õ‡¨®‡≠ç?\n",
      "\n",
      "**Pure Odia:**\n",
      "‡¨ï‡≠á‡¨Æ‡¨ø‡¨§‡¨ø ‡¨Ö‡¨õ‡¨®‡≠ç‡¨§‡¨ø?\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-flash\")\n",
    "response = model.generate_content(\"You are a native of Western Odisha. Translate How are you? to Sambalpuri and also pure Odia. Give only translated text as output. Remember it should be in Odia Script\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45c1db-d637-472b-9f87-ae652aa7d48d",
   "metadata": {},
   "source": [
    "## Listing available Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e564238e-aca2-4759-a65f-c8d9a07bd86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001 ‚Üí ['embedText', 'countTextTokens']\n",
      "models/gemini-2.5-flash ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-pro ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp ‚Üí ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-001 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-exp-image-generation ‚Üí ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.0-flash-lite-001 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview-02-05 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.0-flash-lite-preview ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-exp-1206 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-tts ‚Üí ['countTokens', 'generateContent']\n",
      "models/gemini-2.5-pro-preview-tts ‚Üí ['countTokens', 'generateContent', 'batchGenerateContent']\n",
      "models/gemma-3-1b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemma-3-4b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemma-3-12b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemma-3-27b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e4b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemma-3n-e2b-it ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemini-flash-latest ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-flash-lite-latest ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-pro-latest ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image-preview ‚Üí ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-image ‚Üí ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-preview-09-2025 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-2.5-flash-lite-preview-09-2025 ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-3-pro-preview ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-3-flash-preview ‚Üí ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "models/gemini-3-pro-image-preview ‚Üí ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/nano-banana-pro-preview ‚Üí ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "models/gemini-robotics-er-1.5-preview ‚Üí ['generateContent', 'countTokens']\n",
      "models/gemini-2.5-computer-use-preview-10-2025 ‚Üí ['generateContent', 'countTokens']\n",
      "models/deep-research-pro-preview-12-2025 ‚Üí ['generateContent', 'countTokens']\n",
      "models/embedding-001 ‚Üí ['embedContent']\n",
      "models/text-embedding-004 ‚Üí ['embedContent']\n",
      "models/gemini-embedding-exp-03-07 ‚Üí ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-exp ‚Üí ['embedContent', 'countTextTokens', 'countTokens']\n",
      "models/gemini-embedding-001 ‚Üí ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "models/aqa ‚Üí ['generateAnswer']\n",
      "models/imagen-4.0-generate-preview-06-06 ‚Üí ['predict']\n",
      "models/imagen-4.0-ultra-generate-preview-06-06 ‚Üí ['predict']\n",
      "models/imagen-4.0-generate-001 ‚Üí ['predict']\n",
      "models/imagen-4.0-ultra-generate-001 ‚Üí ['predict']\n",
      "models/imagen-4.0-fast-generate-001 ‚Üí ['predict']\n",
      "models/veo-2.0-generate-001 ‚Üí ['predictLongRunning']\n",
      "models/veo-3.0-generate-001 ‚Üí ['predictLongRunning']\n",
      "models/veo-3.0-fast-generate-001 ‚Üí ['predictLongRunning']\n",
      "models/veo-3.1-generate-preview ‚Üí ['predictLongRunning']\n",
      "models/veo-3.1-fast-generate-preview ‚Üí ['predictLongRunning']\n",
      "models/gemini-2.5-flash-native-audio-latest ‚Üí ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025 ‚Üí ['countTokens', 'bidiGenerateContent']\n",
      "models/gemini-2.5-flash-native-audio-preview-12-2025 ‚Üí ['countTokens', 'bidiGenerateContent']\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "models = genai.list_models()\n",
    "\n",
    "for model in models:\n",
    "    print(model.name, \"‚Üí\", model.supported_generation_methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca12459-569c-44a4-9660-c54d0e2a1ade",
   "metadata": {},
   "source": [
    "## Choosing Gemini-3 Flash Preview for task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e18d838-078d-42ee-9496-974a8d2bcb95",
   "metadata": {},
   "source": [
    "Note - All API Keys are replaced by variables a,b,c,d,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d86c1-d034-4e82-b697-5434daf7f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Reliable Gemini 2.5 Flash Batch Inference...\n",
      "‚úÖ 1/100 processed\n",
      "‚úÖ 2/100 processed\n",
      "‚úÖ 3/100 processed\n",
      "‚úÖ 4/100 processed\n",
      "‚úÖ 5/100 processed\n",
      "‚úÖ 6/100 processed\n",
      "‚úÖ 7/100 processed\n",
      "‚úÖ 8/100 processed\n",
      "‚úÖ 9/100 processed\n",
      "‚úÖ 10/100 processed\n",
      "‚úÖ 11/100 processed\n",
      "‚úÖ 12/100 processed\n",
      "‚úÖ 13/100 processed\n",
      "‚úÖ 14/100 processed\n",
      "‚úÖ 15/100 processed\n",
      "‚úÖ 16/100 processed\n",
      "‚úÖ 17/100 processed\n",
      "‚úÖ 18/100 processed\n",
      "‚úÖ 19/100 processed\n",
      "‚úÖ 20/100 processed\n",
      "‚úÖ 21/100 processed\n",
      "‚ùå Error at 22: RetryError[<Future at 0x24da7a5c250 state=finished raised ClientError>]\n",
      "‚ùå Error at 23: RetryError[<Future at 0x24da7a5e1d0 state=finished raised ClientError>]\n",
      "‚ùå Error at 24: RetryError[<Future at 0x24da7a5f100 state=finished raised ClientError>]\n",
      "‚ùå Error at 25: RetryError[<Future at 0x24da7a79690 state=finished raised ClientError>]\n",
      "‚ùå Error at 26: RetryError[<Future at 0x24da7a123b0 state=finished raised ClientError>]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "# 1. Initialize the Client\n",
    "# IMPORTANT: Generate a NEW key in AI Studio. Your previous key was visible in the prompt.\n",
    "client = genai.Client(api_key=a)\n",
    "\n",
    "# 2. Define Research Instructions\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "# 3. Define the Robust Inference Function\n",
    "@retry(wait=wait_random_exponential(min=2, max=60), stop=stop_after_attempt(5))\n",
    "def get_prediction(text):\n",
    "    \"\"\"Calls Gemini 2.5 Flash and manually parses the JSON text.\"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash', # Switched to 2.5 Flash for available quota\n",
    "        contents=text,\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=instructions,\n",
    "            response_mime_type=\"application/json\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    if not response.text:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Clean potential Markdown artifacts and parse manually\n",
    "        json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "        return json.loads(json_str)\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "# 4. Load dataset and run inference\n",
    "df = pd.read_excel(r\"\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "results = []\n",
    "\n",
    "print(\"üöÄ Starting Reliable Gemini 2.5 Flash Batch Inference...\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    english_text = str(row['English_Source']).strip()\n",
    "    \n",
    "    if not english_text or english_text == \"nan\":\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        data = get_prediction(english_text)\n",
    "        \n",
    "        if data and isinstance(data, dict):\n",
    "            results.append({\n",
    "                \"AI_Odia\": data.get('standard_odia', \"PARSE_ERR\"),\n",
    "                \"AI_SBP\": data.get('sambalpuri', \"PARSE_ERR\")\n",
    "            })\n",
    "            print(f\"‚úÖ {index+1}/100 processed\")\n",
    "        else:\n",
    "            results.append({\"AI_Odia\": \"PARSE_ERR\", \"AI_SBP\": \"PARSE_ERR\"})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error at {index+1}: {e}\")\n",
    "        results.append({\"AI_Odia\": \"ERROR\", \"AI_SBP\": \"ERROR\"})\n",
    "    \n",
    "    # CRITICAL: Sleep 15s to stay under the 5 RPM Free Tier limit\n",
    "    time.sleep(15) \n",
    "\n",
    "# 5. Save results\n",
    "df_results = pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "df_results.to_excel(r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\Results\\gemini_flash_outputs.xlsx\", index=False)\n",
    "print(\"üéØ Done! File saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be01e908-0e5d-4f67-960e-c65ce8855d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 processed and SAVED.\n",
      "‚úÖ 2 processed and SAVED.\n",
      "‚úÖ 3 processed and SAVED.\n",
      "‚úÖ 4 processed and SAVED.\n",
      "‚úÖ 5 processed and SAVED.\n",
      "‚úÖ 6 processed and SAVED.\n",
      "‚úÖ 7 processed and SAVED.\n",
      "‚úÖ 8 processed and SAVED.\n",
      "‚úÖ 9 processed and SAVED.\n",
      "‚úÖ 10 processed and SAVED.\n",
      "‚úÖ 11 processed and SAVED.\n",
      "‚úÖ 12 processed and SAVED.\n",
      "‚úÖ 13 processed and SAVED.\n",
      "‚úÖ 14 processed and SAVED.\n",
      "‚úÖ 15 processed and SAVED.\n",
      "‚úÖ 16 processed and SAVED.\n",
      "‚úÖ 17 processed and SAVED.\n",
      "‚úÖ 18 processed and SAVED.\n",
      "‚úÖ 19 processed and SAVED.\n",
      "‚úÖ 20 processed and SAVED.\n",
      "‚ùå Stopped at 21: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 57.025012352s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}\n",
      "Daily quota likely exhausted. Run the script again tomorrow to resume.\n",
      "üéØ Session complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. Setup\n",
    "client = genai.Client(api_key=a)\n",
    "checkpoint_file = r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\gemini_flash_checkpoints.csv\"\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_excel(r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "\n",
    "# 3. Resume Logic: Check which rows are already done\n",
    "processed_indices = []\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "    processed_indices = checkpoint_df['original_index'].tolist()\n",
    "    print(f\"üîÑ Resuming... {len(processed_indices)} rows already finished.\")\n",
    "\n",
    "# 4. Open CSV in 'append' mode\n",
    "with open(checkpoint_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['original_index', 'English_Source', 'AI_Odia', 'AI_SBP'])\n",
    "    \n",
    "    # Write header only if file is new\n",
    "    if not processed_indices:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows we've already done\n",
    "        if index in processed_indices:\n",
    "            continue\n",
    "            \n",
    "        english_text = str(row['English_Source']).strip()\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-3-flash-preview',\n",
    "                contents=english_text,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    system_instruction=instructions,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Clean and Parse\n",
    "            json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Save IMMEDIATELY to disk\n",
    "            writer.writerow({\n",
    "                'original_index': index,\n",
    "                'English_Source': english_text,\n",
    "                'AI_Odia': data.get('standard_odia'),\n",
    "                'AI_SBP': data.get('sambalpuri')\n",
    "            })\n",
    "            f.flush() # Forces Windows to write to the file now\n",
    "            \n",
    "            print(f\"‚úÖ {index+1} processed and SAVED.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stopped at {index+1}: {e}\")\n",
    "            print(\"Daily quota likely exhausted. Run the script again tomorrow to resume.\")\n",
    "            break \n",
    "        \n",
    "        time.sleep(15) # Stay under 5 RPM\n",
    "\n",
    "print(\"üéØ Session complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9880495a-eade-4c74-b463-ece55fca9ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resuming... 20 rows already finished.\n",
      "‚úÖ 21 processed and SAVED.\n",
      "‚úÖ 22 processed and SAVED.\n",
      "‚úÖ 23 processed and SAVED.\n",
      "‚úÖ 24 processed and SAVED.\n",
      "‚úÖ 25 processed and SAVED.\n",
      "‚úÖ 26 processed and SAVED.\n",
      "‚úÖ 27 processed and SAVED.\n",
      "‚úÖ 28 processed and SAVED.\n",
      "‚úÖ 29 processed and SAVED.\n",
      "‚úÖ 30 processed and SAVED.\n",
      "‚úÖ 31 processed and SAVED.\n",
      "‚úÖ 32 processed and SAVED.\n",
      "‚úÖ 33 processed and SAVED.\n",
      "‚úÖ 34 processed and SAVED.\n",
      "‚úÖ 35 processed and SAVED.\n",
      "‚úÖ 36 processed and SAVED.\n",
      "‚úÖ 37 processed and SAVED.\n",
      "‚úÖ 38 processed and SAVED.\n",
      "‚úÖ 39 processed and SAVED.\n",
      "‚úÖ 40 processed and SAVED.\n",
      "‚úÖ 41 processed and SAVED.\n",
      "‚ùå Stopped at 42: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 35.950295796s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Daily quota likely exhausted. Run the script again tomorrow to resume.\n",
      "üéØ Session complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. Setup\n",
    "client = genai.Client(api_key=b)\n",
    "checkpoint_file = r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\gemini_flash_checkpoints.csv\"\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_excel(r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "\n",
    "# 3. Resume Logic: Check which rows are already done\n",
    "processed_indices = []\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "    processed_indices = checkpoint_df['original_index'].tolist()\n",
    "    print(f\"üîÑ Resuming... {len(processed_indices)} rows already finished.\")\n",
    "\n",
    "# 4. Open CSV in 'append' mode\n",
    "with open(checkpoint_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['original_index', 'English_Source', 'AI_Odia', 'AI_SBP'])\n",
    "    \n",
    "    # Write header only if file is new\n",
    "    if not processed_indices:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows we've already done\n",
    "        if index in processed_indices:\n",
    "            continue\n",
    "            \n",
    "        english_text = str(row['English_Source']).strip()\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-3-flash-preview',\n",
    "                contents=english_text,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    system_instruction=instructions,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Clean and Parse\n",
    "            json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Save IMMEDIATELY to disk\n",
    "            writer.writerow({\n",
    "                'original_index': index,\n",
    "                'English_Source': english_text,\n",
    "                'AI_Odia': data.get('standard_odia'),\n",
    "                'AI_SBP': data.get('sambalpuri')\n",
    "            })\n",
    "            f.flush() # Forces Windows to write to the file now\n",
    "            \n",
    "            print(f\"‚úÖ {index+1} processed and SAVED.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stopped at {index+1}: {e}\")\n",
    "            print(\"Daily quota likely exhausted. Run the script again tomorrow to resume.\")\n",
    "            break \n",
    "        \n",
    "        time.sleep(15) # Stay under 5 RPM\n",
    "\n",
    "print(\"üéØ Session complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bc086d-0154-4051-a089-b31ee288943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resuming... 41 rows already finished.\n",
      "‚úÖ 42 processed and SAVED.\n",
      "‚úÖ 43 processed and SAVED.\n",
      "‚úÖ 44 processed and SAVED.\n",
      "‚úÖ 45 processed and SAVED.\n",
      "‚úÖ 46 processed and SAVED.\n",
      "‚úÖ 47 processed and SAVED.\n",
      "‚úÖ 48 processed and SAVED.\n",
      "‚úÖ 49 processed and SAVED.\n",
      "‚úÖ 50 processed and SAVED.\n",
      "‚úÖ 51 processed and SAVED.\n",
      "‚úÖ 52 processed and SAVED.\n",
      "‚úÖ 53 processed and SAVED.\n",
      "‚úÖ 54 processed and SAVED.\n",
      "‚úÖ 55 processed and SAVED.\n",
      "‚úÖ 56 processed and SAVED.\n",
      "‚úÖ 57 processed and SAVED.\n",
      "‚úÖ 58 processed and SAVED.\n",
      "‚úÖ 59 processed and SAVED.\n",
      "‚úÖ 60 processed and SAVED.\n",
      "‚úÖ 61 processed and SAVED.\n",
      "‚úÖ 62 processed and SAVED.\n",
      "‚ùå Stopped at 63: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 14.103625768s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-3-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}\n",
      "Daily quota likely exhausted. Run the script again tomorrow to resume.\n",
      "üéØ Session complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. Setup\n",
    "client = genai.Client(api_key=c)\n",
    "checkpoint_file = r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\gemini_flash_checkpoints.csv\"\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_excel(r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "\n",
    "# 3. Resume Logic: Check which rows are already done\n",
    "processed_indices = []\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "    processed_indices = checkpoint_df['original_index'].tolist()\n",
    "    print(f\"üîÑ Resuming... {len(processed_indices)} rows already finished.\")\n",
    "\n",
    "# 4. Open CSV in 'append' mode\n",
    "with open(checkpoint_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['original_index', 'English_Source', 'AI_Odia', 'AI_SBP'])\n",
    "    \n",
    "    # Write header only if file is new\n",
    "    if not processed_indices:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows we've already done\n",
    "        if index in processed_indices:\n",
    "            continue\n",
    "            \n",
    "        english_text = str(row['English_Source']).strip()\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-3-flash-preview',\n",
    "                contents=english_text,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    system_instruction=instructions,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Clean and Parse\n",
    "            json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Save IMMEDIATELY to disk\n",
    "            writer.writerow({\n",
    "                'original_index': index,\n",
    "                'English_Source': english_text,\n",
    "                'AI_Odia': data.get('standard_odia'),\n",
    "                'AI_SBP': data.get('sambalpuri')\n",
    "            })\n",
    "            f.flush() # Forces Windows to write to the file now\n",
    "            \n",
    "            print(f\"‚úÖ {index+1} processed and SAVED.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stopped at {index+1}: {e}\")\n",
    "            print(\"Daily quota likely exhausted. Run the script again tomorrow to resume.\")\n",
    "            break \n",
    "        \n",
    "        time.sleep(15) # Stay under 5 RPM\n",
    "\n",
    "print(\"üéØ Session complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a76530f7-061f-41f4-9df4-07cc44f012c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resuming... 62 rows already finished.\n",
      "‚úÖ 63 processed and SAVED.\n",
      "‚úÖ 64 processed and SAVED.\n",
      "‚úÖ 65 processed and SAVED.\n",
      "‚úÖ 66 processed and SAVED.\n",
      "‚úÖ 67 processed and SAVED.\n",
      "‚úÖ 68 processed and SAVED.\n",
      "‚úÖ 69 processed and SAVED.\n",
      "‚úÖ 70 processed and SAVED.\n",
      "‚úÖ 71 processed and SAVED.\n",
      "‚úÖ 72 processed and SAVED.\n",
      "‚úÖ 73 processed and SAVED.\n",
      "‚úÖ 74 processed and SAVED.\n",
      "‚úÖ 75 processed and SAVED.\n",
      "‚úÖ 76 processed and SAVED.\n",
      "‚úÖ 77 processed and SAVED.\n",
      "‚úÖ 78 processed and SAVED.\n",
      "‚úÖ 79 processed and SAVED.\n",
      "‚úÖ 80 processed and SAVED.\n",
      "‚úÖ 81 processed and SAVED.\n",
      "‚úÖ 82 processed and SAVED.\n",
      "‚úÖ 83 processed and SAVED.\n",
      "‚ùå Stopped at 84: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-3-flash\\nPlease retry in 40.827809729s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-3-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Daily quota likely exhausted. Run the script again tomorrow to resume.\n",
      "üéØ Session complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. Setup\n",
    "client = genai.Client(api_key=d)\n",
    "checkpoint_file = r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\gemini_flash_checkpoints.csv\"\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_excel(r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "\n",
    "# 3. Resume Logic: Check which rows are already done\n",
    "processed_indices = []\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "    processed_indices = checkpoint_df['original_index'].tolist()\n",
    "    print(f\"üîÑ Resuming... {len(processed_indices)} rows already finished.\")\n",
    "\n",
    "# 4. Open CSV in 'append' mode\n",
    "with open(checkpoint_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['original_index', 'English_Source', 'AI_Odia', 'AI_SBP'])\n",
    "    \n",
    "    # Write header only if file is new\n",
    "    if not processed_indices:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows we've already done\n",
    "        if index in processed_indices:\n",
    "            continue\n",
    "            \n",
    "        english_text = str(row['English_Source']).strip()\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-3-flash-preview',\n",
    "                contents=english_text,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    system_instruction=instructions,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Clean and Parse\n",
    "            json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Save IMMEDIATELY to disk\n",
    "            writer.writerow({\n",
    "                'original_index': index,\n",
    "                'English_Source': english_text,\n",
    "                'AI_Odia': data.get('standard_odia'),\n",
    "                'AI_SBP': data.get('sambalpuri')\n",
    "            })\n",
    "            f.flush() # Forces Windows to write to the file now\n",
    "            \n",
    "            print(f\"‚úÖ {index+1} processed and SAVED.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stopped at {index+1}: {e}\")\n",
    "            print(\"Daily quota likely exhausted. Run the script again tomorrow to resume.\")\n",
    "            break \n",
    "        \n",
    "        time.sleep(15) # Stay under 5 RPM\n",
    "\n",
    "print(\"üéØ Session complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f3cb901-efdf-4cd5-ae9a-2e15d24fb4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Resuming... 83 rows already finished.\n",
      "‚úÖ 84 processed and SAVED.\n",
      "‚úÖ 85 processed and SAVED.\n",
      "‚úÖ 86 processed and SAVED.\n",
      "‚úÖ 87 processed and SAVED.\n",
      "‚úÖ 88 processed and SAVED.\n",
      "‚úÖ 89 processed and SAVED.\n",
      "‚úÖ 90 processed and SAVED.\n",
      "‚úÖ 91 processed and SAVED.\n",
      "‚úÖ 92 processed and SAVED.\n",
      "‚úÖ 93 processed and SAVED.\n",
      "‚úÖ 94 processed and SAVED.\n",
      "‚úÖ 95 processed and SAVED.\n",
      "‚úÖ 96 processed and SAVED.\n",
      "‚úÖ 97 processed and SAVED.\n",
      "‚úÖ 98 processed and SAVED.\n",
      "‚úÖ 99 processed and SAVED.\n",
      "‚úÖ 100 processed and SAVED.\n",
      "üéØ Session complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import csv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# 1. Setup\n",
    "client = genai.Client(api_key=e)\n",
    "checkpoint_file = r\"X:\\Siddhanta\\IIIT NR\\6th Semester\\Project_Sambalpuri\\github\\Sambalpuri_Sieve_SLM_Evaluation\\gemini_flash_checkpoints.csv\"\n",
    "instructions = (\n",
    "    \"You are an expert linguist specializing in the dialects of Odisha, India. \"\n",
    "    \"Translate the English text into: 1) Standard Odia and 2) Sambalpuri dialect. \"\n",
    "    \"Use Odia script. Format your output strictly as a JSON object: \"\n",
    "    \"{'standard_odia': '...', 'sambalpuri': '...'}. Do not provide English explanations.\"\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Load Dataset\n",
    "df = pd.read_excel(r\"\\Sambalpuri_Sieve_SLM_Evaluation\\Data\\sambalpuri_std_odia_parallel_corpus.xlsx\")\n",
    "\n",
    "# 3. Resume Logic: Check which rows are already done\n",
    "processed_indices = []\n",
    "if os.path.exists(checkpoint_file):\n",
    "    checkpoint_df = pd.read_csv(checkpoint_file)\n",
    "    processed_indices = checkpoint_df['original_index'].tolist()\n",
    "    print(f\"üîÑ Resuming... {len(processed_indices)} rows already finished.\")\n",
    "\n",
    "# 4. Open CSV in 'append' mode\n",
    "with open(checkpoint_file, mode='a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['original_index', 'English_Source', 'AI_Odia', 'AI_SBP'])\n",
    "    \n",
    "    # Write header only if file is new\n",
    "    if not processed_indices:\n",
    "        writer.writeheader()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # Skip rows we've already done\n",
    "        if index in processed_indices:\n",
    "            continue\n",
    "            \n",
    "        english_text = str(row['English_Source']).strip()\n",
    "        \n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model='gemini-3-flash-preview',\n",
    "                contents=english_text,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    system_instruction=instructions,\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Clean and Parse\n",
    "            json_str = re.sub(r'```json\\s*|```', '', response.text).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Save IMMEDIATELY to disk\n",
    "            writer.writerow({\n",
    "                'original_index': index,\n",
    "                'English_Source': english_text,\n",
    "                'AI_Odia': data.get('standard_odia'),\n",
    "                'AI_SBP': data.get('sambalpuri')\n",
    "            })\n",
    "            f.flush() # Forces Windows to write to the file now\n",
    "            \n",
    "            print(f\"‚úÖ {index+1} processed and SAVED.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stopped at {index+1}: {e}\")\n",
    "            print(\"Daily quota likely exhausted. Run the script again tomorrow to resume.\")\n",
    "            break \n",
    "        \n",
    "        time.sleep(15) # Stay under 5 RPM\n",
    "\n",
    "print(\"üéØ Session complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpuenv]",
   "language": "python",
   "name": "conda-env-gpuenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
